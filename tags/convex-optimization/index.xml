<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Convex Optimization |</title><link>https://cadenzacoda.github.io/portfolio/tags/convex-optimization/</link><atom:link href="https://cadenzacoda.github.io/portfolio/tags/convex-optimization/index.xml" rel="self" type="application/rss+xml"/><description>Convex Optimization</description><generator>HugoBlox Kit (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 01 Dec 2025 00:00:00 +0000</lastBuildDate><image><url>https://cadenzacoda.github.io/portfolio/media/icon_hu_982c5d63a71b2961.png</url><title>Convex Optimization</title><link>https://cadenzacoda.github.io/portfolio/tags/convex-optimization/</link></image><item><title>Constrained Policy Optimization via Sampling-Based Weight-Space Projection</title><link>https://cadenzacoda.github.io/portfolio/publications/constrained-policy-optimization/</link><pubDate>Mon, 01 Dec 2025 00:00:00 +0000</pubDate><guid>https://cadenzacoda.github.io/portfolio/publications/constrained-policy-optimization/</guid><description/></item><item><title>Sampling-Based Constrained Policy Optimization</title><link>https://cadenzacoda.github.io/portfolio/projects/constrained-policy-opt/</link><pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate><guid>https://cadenzacoda.github.io/portfolio/projects/constrained-policy-opt/</guid><description>&lt;p&gt;&lt;strong&gt;Principal Researcher&lt;/strong&gt; (Sep 2025 &amp;mdash; Dec 2025)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Proposed a sampling-based weight-space projection framework for enforcing safety constraints during policy updates, enabling scalable safe learning for large neural policies.&lt;/li&gt;
&lt;li&gt;Formulated policy optimization as a convex projection in parameter space, with theoretical guarantees that projected updates preserve objective improvement.&lt;/li&gt;
&lt;li&gt;Derived a sufficient stability condition linking weight updates to closed-loop constraint satisfaction, and embedded it directly into the optimization pipeline.&lt;/li&gt;
&lt;li&gt;Empirically demonstrated complete rejection of harmful supervision and safe performance gains in regression and imitation learning under adversarial experts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tech:&lt;/strong&gt; PyTorch, Convex Optimization, Reinforcement Learning, Safe Learning.&lt;/p&gt;</description></item></channel></rss>